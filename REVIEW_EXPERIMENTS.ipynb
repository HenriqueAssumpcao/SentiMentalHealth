{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJZFUhYPAiFw"
   },
   "source": [
    "# **0**. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_5Q8tjk_h77"
   },
   "outputs": [],
   "source": [
    "ON_COLAB=False\n",
    "if ON_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    BASEDIR='/content/drive/My Drive/MentalHealthShared/'\n",
    "    PYTHONDIR=BASEDIR+'src'\n",
    "    RESULTSDIR=BASEDIR+'results/'\n",
    "    MODELSDIR=BASEDIR+'model/'\n",
    "    DATADIR=BASEDIR+'data/'\n",
    "    import models\n",
    "    import pytorchtools\n",
    "    from utils import createTensorDataset\n",
    "    from training_functions import load_df, compute_bin_weights, save_stats_tensors, load_stats_tensors, get_znorm_params, get_subreddit_range, split_indices, get_subreddit_weights\n",
    "else:\n",
    "    import os\n",
    "    BASEDIR = os.getcwd() + \"/\"\n",
    "    dirs = [\"src\",\"results\",\"model\",\"data\"]\n",
    "    for dirc in dirs:\n",
    "        if dirc not in os.listdir(): \n",
    "            os.makedirs(os.path.join(BASEDIR,dirc))\n",
    "    PYTHONDIR=BASEDIR+'src/'\n",
    "    RESULTSDIR=BASEDIR+'results/'\n",
    "    MODELSDIR=BASEDIR+'model/'\n",
    "    DATADIR=BASEDIR+'data/'\n",
    "    from src import models\n",
    "    from src import pytorchtools\n",
    "    from src.utils import createTensorDataset\n",
    "    from src.training_functions import load_df, compute_bin_weights, save_stats_tensors, load_stats_tensors, get_znorm_params, get_subreddit_range, split_indices, get_subreddit_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUSUqiiWB_wJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device == torch.device('cuda'):\n",
    "    print(f\"Device successfully set to cuda\")\n",
    "else:\n",
    "    print(\"WARNING! DEVICE IS NOT SET TO CUDA\")\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig5eK4D8ApCn"
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import sys\n",
    "sys.path.append(PYTHONDIR)\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import pdb\n",
    "import importlib\n",
    "import itertools\n",
    "import pprint\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdCFbGprpA5s"
   },
   "source": [
    "# **1** Build the source data\n",
    "\n",
    "* Build the source data in order to predict the EmT based on the sequence of comments in a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "du4-sr2mBAmR"
   },
   "outputs": [],
   "source": [
    "# DEFINE SUBREDDITS\n",
    "SUBREDDITS  = ['Anxiety','bipolar','depression','SuicideWatch'] \n",
    "subreddit2title = {'depression':'DEP','suicidewatch':'SUI','anxiety':'ANX','bipolar':'BIP'}\n",
    "\n",
    "EXTENSION = '.pkl'\n",
    "STRATIFIED = True  # If true, will apply a stratified K-fold cross-validation to the dataset.\n",
    "ZNORMALIZE = False # If true, will apply a z-normalization to the dataset\n",
    "KEEP_TEXT = True # Only True if using Section 6 for Case Study\n",
    "\n",
    "FILTERED=True # If true will use filtered seq_len for the threads\n",
    "BIN_WIDTH=0.2 # Controls the width of the bins used to calculate the weighted L1 loss\n",
    "MIN_VALUE = -1 # Controls the minimum output value(set to -1)\n",
    "\n",
    "\n",
    "INCLUDE_TARGET = 0\n",
    "INCLUDE_THREAD_COMMENTS = 0\n",
    "\n",
    "\n",
    "MAX_BRANCH_LEN = 16   # not including authors' last comment\n",
    "MAX_THREAD_LEN = 64   # not including authors' last comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wv1F_eR3El09",
    "outputId": "2f26453a-968a-4d4b-d220-82c0138189fc"
   },
   "outputs": [],
   "source": [
    "suffix='_distilbert_filtered_posts' + EXTENSION\n",
    "df_list = {subreddit:load_df(DATADIR+subreddit+suffix, MAX_THREAD_LEN) \\\n",
    "           for subreddit in ['depression','Anxiety','bipolar','SuicideWatch']}\n",
    "\n",
    "post_df = pd.concat((df_list[subreddit] for subreddit in SUBREDDITS), keys=SUBREDDITS)\n",
    "del df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyZzK_aB6YHJ",
    "outputId": "d800a3a6-9fc4-4bde-f570-9f17f726a46d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# post_df = pd.concat((load_df(DATADIR+subreddit+suffix, MAX_THREAD_LEN) \\\n",
    "#                         for subreddit in SUBREDDITS),keys=SUBREDDITS)\n",
    "\n",
    "\n",
    "# TODO: it seems that we are keeping everything if KEEP_TEXT. is this really necessary?\n",
    "if not KEEP_TEXT:\n",
    "  post_df = post_df[['created_utc', 'seq_len','score', 'features', 'filtered_seqlen','valid_branches']]\n",
    "\n",
    "# new strategy to construct observations: follow branches of every discussion tree \n",
    "#post_df.drop(columns=['valid_branches'],inplace=True)\n",
    "\n",
    "if FILTERED:\n",
    "    # dropna on filtered_seqlen, then replace seq_len by filtered_seqlen\n",
    "    post_df.dropna(subset=['filtered_seqlen'], inplace=True)\n",
    "    post_df.filtered_seqlen = post_df.filtered_seqlen.astype(int)\n",
    "\n",
    "    post_df.drop(columns='seq_len',inplace=True)\n",
    "    post_df.rename(columns={'filtered_seqlen':'seq_len'},inplace=True)\n",
    "else:\n",
    "    post_df.drop(columns='filtered_seqlen',inplace=True)\n",
    "\n",
    "print(f'Fraction of threads that had to be truncated: {(post_df.seq_len>(MAX_THREAD_LEN+1)).mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt5koa7q5QVF",
    "outputId": "ba005eb6-ef00-4588-ae06-c3c46efcc377"
   },
   "outputs": [],
   "source": [
    "# TODO: define constants upfront\n",
    "if ZNORMALIZE:\n",
    "  prefix = ''\n",
    "else:\n",
    "  prefix = 'unnorm_'\n",
    "\n",
    "if ZNORMALIZE:\n",
    "    src_m, src_s = get_znorm_params(post_df)\n",
    "else:\n",
    "    shape = [1,post_df.iloc[0].features.shape[-1]]\n",
    "    src_m = torch.zeros(shape)\n",
    "    src_s = torch.ones(shape)\n",
    "\n",
    "save_stats_tensors(src_m,src_s,f'{BASEDIR}data/{prefix}')\n",
    "\n",
    "score_m = float(src_m[0,-2])\n",
    "score_s = float(src_s[0,-2])\n",
    "\n",
    "print(f'Average score in dataset is {score_m}')\n",
    "\n",
    "subreddit2range = get_subreddit_range()\n",
    "print(subreddit2range[SUBREDDITS[0]])\n",
    "\n",
    "# TODO: define constants upfront\n",
    "suffix = \"random\"\n",
    "if STRATIFIED:\n",
    "  suffix += '_strat'\n",
    "\n",
    "# TODO: place indexing in a new function and explain what it does\n",
    "# get indices\n",
    "if len(SUBREDDITS) == 4:\n",
    "    train_inds, valid_inds, test_inds  = split_indices(post_df)\n",
    "else:\n",
    "    subreddit = SUBREDDITS[0]\n",
    "    with open(f'{DATADIR}{subreddit}_{suffix}_splits.pkl','rb') as infile:\n",
    "        splits = pickle.load(infile)\n",
    "        train_locs =  [(subreddit,loc) for loc in splits[0]]\n",
    "        valid_locs =  [(subreddit,loc) for loc in splits[1]]\n",
    "        test_locs  =  [(subreddit,loc) for loc in splits[2]]\n",
    "\n",
    "    train_inds = post_df.index.get_indexer_for(train_locs)\n",
    "    valid_inds = post_df.index.get_indexer_for(valid_locs)\n",
    "    test_inds  = post_df.index.get_indexer_for(test_locs)\n",
    "\n",
    "\n",
    "\n",
    "# compute weights for Weighted L1 Loss\n",
    "subreddit2weights = get_subreddit_weights(post_df, BIN_WIDTH,MIN_VALUE)\n",
    "print(subreddit2weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heaO2d6xcAvh"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: place the dataset generation in a function\n",
    "\n",
    "\n",
    "print('Creating src')\n",
    "\n",
    "print('Creating y')\n",
    "y = torch.Tensor(post_df.apply(lambda p: p.score[p.seq_len-1], axis=1).values)\n",
    "\n",
    "print('Creating src_len_series')\n",
    "src_len_series = post_df.seq_len-1\n",
    "max_length=MAX_THREAD_LEN\n",
    "src = nn.utils.rnn.pad_sequence(\n",
    "[ p.features[:min(MAX_THREAD_LEN,p.seq_len-1),:] for index, p in post_df.iterrows()], batch_first=True)\n",
    "# src = nn.utils.rnn.pad_sequence(\n",
    "# [ (p.features[:min(MAX_THREAD_LEN,p.seq_len-1),:]-src_m)/src_s for index, p in post_df.iterrows()], batch_first=True)\n",
    "print(f\"GRU src tensor size: {src.size()}\")\n",
    "\n",
    "print(f'y tensor size: {y.size()}')\n",
    "\n",
    "if INCLUDE_TARGET:\n",
    "  tgt = nn.utils.rnn.pad_sequence(\n",
    "    [(p.features[b[-2]]-src_m)/src_s for index, p in post_df.iterrows() for b in p.valid_branches],\n",
    "  batch_first=True)\n",
    "else:\n",
    "  tgt = None\n",
    "\n",
    "  # clean up memory\n",
    "  #if (not TEST) and (not KEEP_TEXT):\n",
    "  if (not KEEP_TEXT):\n",
    "    del post_df\n",
    "\n",
    "  print('Creating dataset')\n",
    "  if USE_GRU:\n",
    "    dataset = createTensorDataset(src, src_len_series, y, max_length=max_length) # all threads, lim 63 comments\n",
    "    del src\n",
    "  \n",
    "  del src_len_series, tgt, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MLMLb6LAidE",
    "outputId": "5c277d0a-7c5b-416a-a289-2e17bec8c37e"
   },
   "outputs": [],
   "source": [
    "batch = dataset[0]\n",
    "EMBEDDING_DIM = batch[0].shape[-1]\n",
    "print(f\"embedding dimension for GRU: {EMBEDDING_DIM}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B3WB_yOr20w"
   },
   "source": [
    "# **2**. Analyzing the effect of etiquette words on the Vader Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7mF3ORElR7b"
   },
   "source": [
    "## Plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dIXmXSWklQc"
   },
   "outputs": [],
   "source": [
    "def calculate_KDF(fluctuations_df):\n",
    "\n",
    "    x = fluctuations_df['score_before'].to_numpy(dtype=float)\n",
    "    y = fluctuations_df['score_after'].to_numpy(dtype=float)\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    ymin = y.min()\n",
    "    ymax = y.max() \n",
    "    # X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    X, Y = np.mgrid[xmin:xmax:40j, ymin:ymax:40j]\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = stats.gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, X.shape)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F72xvLTPsGn-"
   },
   "outputs": [],
   "source": [
    "def plot_score_dist(scores,title,n_bins=20,log_y=False):\n",
    "    N = len(scores)\n",
    "    fig, axs = plt.subplots(1,N, tight_layout=True,figsize=(5 * N,3),sharey=True)\n",
    "\n",
    "    # N, bins, patches = axs[0].hist(scores, bins=n_bins)\n",
    "\n",
    "    # axs[0].set_title(f\"Emotional Tone Histogram ({title})\")\n",
    "    # axs[0].set_xlabel(\"EmT\")\n",
    "    # axs[0].set_ylabel(f\"Number of posts and comments\")\n",
    "    # axs[0].axvline(color='k',linestyle='dashed')\n",
    "    # axs[1].set_title(f\"Emotional Tone Histogram ({title})\")\n",
    "    # axs[1].set_xlabel(\"EmT\")\n",
    "    # axs[1].set_ylabel(f\"Number of posts and comments\")\n",
    "    # axs[1].axvline(color='k',linestyle='dashed')\n",
    "    if type(axs) != type(np.array(0)):\n",
    "        axs = [axs]\n",
    "    for ind,ax in enumerate(axs):\n",
    "        N, bins, patches = ax.hist(scores[ind], bins=n_bins)\n",
    "        ax.set_title(f\"Emotional Tone Histogram ({title[ind]})\")\n",
    "        ax.set_xlabel(r\"$\\Delta EmT$\")\n",
    "        if ind == 0:\n",
    "            ax.set_ylabel(f\"Number of posts\")\n",
    "        ax.axvline(color='k',linestyle='dashed')\n",
    "        if (log_y):\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDew2nE8bLia"
   },
   "outputs": [],
   "source": [
    "def plot_fluctuations(fluctuations_df,Z,explanation='w.r.t comments and posts that deviate'):\n",
    "    x = fluctuations_df['score_before_x'].to_numpy(dtype=float)\n",
    "    y = fluctuations_df['score_after_y'].to_numpy(dtype=float)\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    ymin = y.min()\n",
    "    ymax = y.max() \n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "            extent=[xmin, xmax, ymin, ymax])\n",
    "    #ax.plot(x, y, 'k.', markersize=2)\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "\n",
    "    plt.plot([0,0],[-1,1],'dimgray',linestyle='dotted')\n",
    "    plt.plot([-1,1],[0,0],'dimgray',linestyle='dotted')\n",
    "    plt.plot([-1,1],[-1,1],'dimgray',label='y = x',linestyle='dashed')\n",
    "    legend = ax.legend(loc='upper left', shadow=True, fontsize='medium')\n",
    "    # ax.scatter(x[:50], y[:50], c='k', s=5, edgecolor='')\n",
    "    # legend.get_frame().set_facecolor('C0')\n",
    "    plt.xlabel(\"EmT before removing Etiquette words\")\n",
    "    plt.ylabel(\"EmT after removing Etiquette words\")\n",
    "    plt.title(f\"Distribution of EmT before vs after ({explanation})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-o3aK1_zlUbi"
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPe8Q9V_hRjZ"
   },
   "outputs": [],
   "source": [
    "def get_fluct_df(post_df,scores,suffix,save_files=True):\n",
    "    score_fluctuations_df = pd.DataFrame(index=list(range(len(scores))),columns=['id','score_before','score_after'])\n",
    "    curr_idx = 0\n",
    "    for post in tqdm(range(post_df.shape[0])):\n",
    "        curr_iloc = post_df.iloc[post]\n",
    "        if suffix == \"_before\":\n",
    "            score_fluctuations_df.iloc[curr_idx] = [curr_iloc.name[1],curr_iloc.score[0],0]\n",
    "        else:\n",
    "             score_fluctuations_df.iloc[curr_idx] = [curr_iloc.name[1],0,curr_iloc.score[0]]\n",
    "        comment_idx = 1\n",
    "        for comment in curr_iloc.comments[:(curr_iloc.seq_len - 1)]:\n",
    "            score_fluctuations_df.iloc[curr_idx + comment_idx] = [comment,0,curr_iloc.score[comment_idx]]\n",
    "            comment_idx += 1\n",
    "        curr_idx += comment_idx\n",
    "\n",
    "    post_only_df = pd.DataFrame(index=list(range(len(post_df))),columns=['id','post_score_before','post_score_after'])\n",
    "    if suffix == \"_before\":\n",
    "        for post in tqdm(range(len(post_df))):\n",
    "            post_only_df.iloc[post] = [post_df.iloc[post].name[1],post_df.iloc[post].score[0],0]\n",
    "    else:\n",
    "        for post in tqdm(range(len(post_df))):\n",
    "            post_only_df.iloc[post] = [post_df.iloc[post].name[1],0,post_df.iloc[post].score[0]]\n",
    "\n",
    "    if save_files:\n",
    "        post_only_df.to_pickle(DATADIR + f\"post_only_fluct{suffix}.pkl\")\n",
    "        score_fluctuations_df.to_pickle(DATADIR + f\"score_fluct{suffix}.pkl\")\n",
    "    return score_fluctuations_df,post_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ih32JuUQsb_O"
   },
   "outputs": [],
   "source": [
    "CREATE_NO_THX_SCORES = False\n",
    "CREATE_THX_SCORES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNyCIkp1r-OA"
   },
   "outputs": [],
   "source": [
    "if CREATE_NO_THX_SCORES:  \n",
    "    no_thx_scores = []\n",
    "    for post in tqdm(range(post_df.shape[0])):\n",
    "        no_thx_scores.append(post_df.iloc[post].score[:post_df.iloc[post].seq_len])\n",
    "    no_thx_scores = list(itertools.chain.from_iterable(no_thx_scores))\n",
    "    pickle.dump(no_thx_scores,open(DATADIR  + 'no_thx_scores.pkl','wb'))\n",
    "else:\n",
    "    no_thx_scores = pickle.load(open(DATADIR  + 'no_thx_scores.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm9vSvvps-ic"
   },
   "outputs": [],
   "source": [
    "if CREATE_THX_SCORES:  \n",
    "    thx_scores = []\n",
    "    for post in range(post_df.shape[0]):\n",
    "        thx_scores.append(post_df.iloc[post].score[:post_df.iloc[post].seq_len])\n",
    "    thx_scores = list(itertools.chain.from_iterable(thx_scores))\n",
    "    pickle.dump(thx_scores,open(DATADIR + \"no_thx_2017/\" 'thx_scores.pkl','wb'))\n",
    "else:\n",
    "    thx_scores = pickle.load(open(DATADIR  + 'thx_scores.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "3WlsXBQ_sSxi",
    "outputId": "edd7d148-0333-4cb8-a2c7-5b162a2fcb1d"
   },
   "outputs": [],
   "source": [
    "plot_score_dist([thx_scores],title=['filtered','unfiltered'],n_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4n9TdpeHW9a"
   },
   "outputs": [],
   "source": [
    "# POSTS + COMMENTS\n",
    "STEP_1 = False\n",
    "STEP_2 = True\n",
    "if STEP_1:\n",
    "    CREATE_FLUCTUATIONS_DF = False\n",
    "    if DATADIR == BASEDIR+'data/':\n",
    "        suffix = \"_before\"\n",
    "        scores = thx_scores\n",
    "    else:\n",
    "        suffix = \"_after\"\n",
    "        scores = no_thx_scores\n",
    "\n",
    "    if CREATE_FLUCTUATIONS_DF:\n",
    "        score_df,post_only_df = get_fluct_df(post_df,scores,suffix)\n",
    "    else:\n",
    "        score_df_after = pickle.load(open(DATADIR  + f\"score_fluct_after.pkl\",'rb'))\n",
    "        score_df_before = pickle.load(open(DATADIR  + f\"score_fluct_before.pkl\",'rb'))\n",
    "        post_only_df_after = pickle.load(open(DATADIR  + f\"post_only_fluct_after.pkl\",'rb'))\n",
    "        post_only_df_before = pickle.load(open(DATADIR  + f\"post_only_fluct_before.pkl\",'rb'))\n",
    "if STEP_2:\n",
    "    CONCATENATE_DFS = False\n",
    "    if CONCATENATE_DFS:\n",
    "        final_score_df = pd.merge(score_df_before,score_df_after,how='inner',on=['id'])\n",
    "        final_score_df.drop(['score_after_x'],axis=1,inplace=True)\n",
    "        final_score_df.drop(['score_before_y'],axis=1,inplace=True)\n",
    "\n",
    "        final_post_only_df = pd.merge(post_only_df_before,post_only_df_after,how='inner',on=['id'])\n",
    "        final_post_only_df.drop(['post_score_after_x'],axis=1,inplace=True)\n",
    "        final_post_only_df.drop(['post_score_before_y'],axis=1,inplace=True)\n",
    "\n",
    "        final_score_df.to_pickle(DATADIR + \"final_score_fluct_df.pkl\")\n",
    "        final_post_only_df.to_pickle(DATADIR + \"final_post_fluct_df.pkl\")\n",
    "    else:\n",
    "        post_only_df = pd.read_pickle(DATADIR + \"final_post_fluct_df.pkl\")\n",
    "        score_fluct_df = pd.read_pickle(DATADIR + \"final_score_fluct_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_EJ1oKTaDkr"
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "post_counter = 0\n",
    "for i in tqdm(range(len(score_fluct_df))):\n",
    "    if score_fluct_df.iloc[i].id[0] != 'd': # 'd' indicates that the author is a commenter\n",
    "        try:\n",
    "            assert (post_only_df.iloc[post_counter].post_score_before_x == score_fluct_df.iloc[i].score_before_x)\n",
    "            assert (post_only_df.iloc[post_counter].post_score_after_y == score_fluct_df.iloc[i].score_after_y)\n",
    "        except AssertionError:\n",
    "            print(post_only_df.iloc[post_counter])\n",
    "            print(score_fluct_df.iloc[i])\n",
    "        post_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JiTp-h8Zs97"
   },
   "outputs": [],
   "source": [
    "diff_df = score_fluct_df['score_after_y'] - score_fluct_df['score_before_x']\n",
    "post_diff_df = post_only_df['post_score_after_y'] - post_only_df['post_score_before_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0Ogdih4XKoW",
    "outputId": "2b8a14b7-5bdf-406c-e6cf-9563577974c8"
   },
   "outputs": [],
   "source": [
    "diff_df = score_fluct_df['score_after_y'] - score_fluct_df['score_before_x']\n",
    "print(f\"Average deviation from original score w.r.t. to all posts/comments: {diff_df.sum()/diff_df.shape[0]}\")\n",
    "print(f\"Percentage of posts/comments that deviated from the original score: {(sum(diff_df != 0)/diff_df.shape[0])*100}%\")\n",
    "posts_that_deviate = diff_df[diff_df.index[diff_df != 0]]\n",
    "print(f\"Average deviation from original score w.r.t. to posts/comments that deviate: {posts_that_deviate.sum()/posts_that_deviate.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "8yifYOp4gf0t",
    "outputId": "3e314bef-fc20-4cbc-8241-e18d3ca30b50"
   },
   "outputs": [],
   "source": [
    "plot_score_dist([diff_df.to_list()],title=['fluctuations'],n_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kdg62dYPnUoH"
   },
   "outputs": [],
   "source": [
    "z_values_total = calculate_KDF(score_fluct_df)\n",
    "z_values_deviate = calculate_KDF(score_fluct_df.iloc[posts_that_deviate.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "eAieuMCpVOvN",
    "outputId": "f51dfa3f-65ab-4970-cb91-f17c3b1408f9"
   },
   "outputs": [],
   "source": [
    "plot_fluctuations(score_fluct_df,z_values_total,explanation='all comments + posts')\n",
    "plot_fluctuations(score_fluct_df.iloc[posts_that_deviate.index],z_values_deviate,explanation=r'posts + comments w/ $\\Delta EmT \\neq 0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45osseaIfY2i",
    "outputId": "a58de920-ed8c-4eca-9cd4-da411ab8e880"
   },
   "outputs": [],
   "source": [
    "post_diff_df = post_only_df['post_score_after_y'] - post_only_df['post_score_before_x']\n",
    "print(f\"Average deviation from original score w.r.t. to all posts: {post_diff_df.sum()/post_diff_df.shape[0]}\")\n",
    "print(f\"Percentage of posts that deviated from the original score: {(sum(post_diff_df != 0)/post_diff_df.shape[0])*100}%\")\n",
    "posts_only_that_deviate = post_diff_df[post_diff_df.index[post_diff_df != 0]]\n",
    "print(f\"Average deviation from original score w.r.t. to posts that deviate: {posts_only_that_deviate.sum()/posts_only_that_deviate.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tX-YC2NFePig"
   },
   "outputs": [],
   "source": [
    "post_only_df.columns = ['id','score_before_x','score_after_y']\n",
    "post_z_values_total = calculate_KDF(post_only_df)\n",
    "post_z_values_deviate = calculate_KDF(post_only_df.iloc[posts_only_that_deviate.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "r9L3QK-_oIMP",
    "outputId": "bca56ee9-df4f-4d88-8e09-89ca3f289cac"
   },
   "outputs": [],
   "source": [
    "plot_score_dist([post_diff_df.to_list()],n_bins=20,title=[r'fluctuations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "a0iGop98hyaP",
    "outputId": "def7c59a-f2c8-4613-8fb2-1e056dcb2b63"
   },
   "outputs": [],
   "source": [
    "plot_fluctuations(post_only_df,post_z_values_total,explanation='all posts')\n",
    "plot_fluctuations(post_only_df.iloc[posts_only_that_deviate.index],post_z_values_deviate,explanation=r'posts w/ $\\Delta EmT \\neq 0$')\n",
    "# plot_score_dist(post_diff_df.to_list(),n_bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNlXb_hW5N9i"
   },
   "outputs": [],
   "source": [
    "def plot_fluctuations(fluctuations_df,Z,df_x,df_y,title,xlabel,ylabel,explanation='w.r.t comments and posts that deviate'):\n",
    "    x = fluctuations_df[df_x].to_numpy(dtype=float)\n",
    "    y = fluctuations_df[df_y].to_numpy(dtype=float)\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    ymin = y.min()\n",
    "    ymax = y.max() \n",
    "    fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "            extent=[xmin, xmax, ymin, ymax])\n",
    "    #ax.plot(x, y, 'k.', markersize=2)\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "\n",
    "    ax.set_ylim([ymin, ymax])\n",
    "\n",
    "    plt.plot([0,0],[-1,1],'dimgray',linestyle='dotted')\n",
    "    plt.plot([-1,1],[0,0],'dimgray',linestyle='dotted')\n",
    "    #plt.plot([-1,1],[-1,1],'dimgray',label='y = x',linestyle='dashed')\n",
    "    #legend = ax.legend(loc='upper left', shadow=True, fontsize='medium')\n",
    "    # ax.scatter(x[:50], y[:50], c='k', s=5, edgecolor='')\n",
    "    # legend.get_frame().set_facecolor('C0')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgvLAhbm3OAl"
   },
   "outputs": [],
   "source": [
    "score_fluct_df = pd.DataFrame(index=list(range(post_df.shape[0])),columns=['score_before','score_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taSI8PXp33ze"
   },
   "outputs": [],
   "source": [
    "for post in range(post_df.shape[0]):\n",
    "    score_fluct_df.iloc[post]['score_before'] = post_df.iloc[post].score[0]\n",
    "    score_fluct_df.iloc[post]['score_after'] = post_df.iloc[post].score[post_df.iloc[post].seq_len - 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBM9LhHH48el"
   },
   "outputs": [],
   "source": [
    "z_values_fluct = calculate_KDF(score_fluct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "4xxv4S1W5Hxm",
    "outputId": "6e020072-1a3c-4130-c0cd-4f24368d2d93"
   },
   "outputs": [],
   "source": [
    "plot_fluctuations(score_fluct_df,z_values_fluct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ypor_4Dr0md"
   },
   "source": [
    "#**3** Confidence Interval Experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsF-aEEUDLNt"
   },
   "outputs": [],
   "source": [
    "if len(SUBREDDITS) == 4:\n",
    "    SRC_DATASET='all'\n",
    "if len(SUBREDDITS) == 1:\n",
    "    SRC_DATASET=SUBREDDITS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TxnnCrcsAcx"
   },
   "source": [
    "## Normalizing MEAN and XGB w.r.t. real scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KRYsRmU2r9Na",
    "outputId": "fe6e3283-3871-48a0-bc0e-f8b838e1c623"
   },
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(f'{RESULTSDIR}{PREFIX}_{SRC_DATASET}_predictions.csv',index_col=0)\n",
    "tmp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BiGqd9Vsr9Nb",
    "outputId": "2b136f2e-0c28-49df-864a-8cc159e308f4"
   },
   "outputs": [],
   "source": [
    "l1_loss_unnormalized_xgb = (tmp_df['xgb-mse'] - tmp_df['final score']).abs().mean()\n",
    "l1_loss_unnormalized_mean = (tmp_df['mean'] - tmp_df['final score']).abs().mean()\n",
    "print(f\"XGB UNNORMALIZED L1 LOSS: {l1_loss_unnormalized_xgb}\")\n",
    "print(f\"MEAN UNNORMALIZED L1 LOSS: {l1_loss_unnormalized_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDcJCGaMr9Nc"
   },
   "outputs": [],
   "source": [
    "mu_true,std_true = tmp_df['final score'].describe().loc[['mean','std']]\n",
    "mu_pred_xgb,std_pred_xgb = tmp_df['xgb-mse'].describe().loc[['mean','std']]\n",
    "mu_pred_mean,std_pred_mean = tmp_df['mean'].describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lOFEQdar9Nc"
   },
   "outputs": [],
   "source": [
    "tmp_df['xgb-mse'] = (tmp_df['xgb-mse'] - mu_pred_xgb)/std_pred_xgb * std_true + mu_true\n",
    "tmp_df['mean'] = (tmp_df['mean'] - mu_pred_mean)/std_pred_mean * std_true + mu_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCrtbphSr9Nc",
    "outputId": "b994aa51-59b8-47a6-888a-e58afd286dd3"
   },
   "outputs": [],
   "source": [
    "l1_loss_normalized_xgb = (tmp_df['xgb-mse'] - tmp_df['final score']).abs().mean()\n",
    "l1_loss_normalized_mean = (tmp_df['mean'] - tmp_df['final score']).abs().mean()\n",
    "print(f\"XGB NORMALIZED L1 LOSS: {l1_loss_normalized_xgb}\")\n",
    "print(f\"MEAN NORMALIZED L1 LOSS: {l1_loss_normalized_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tTQIiyV30N2"
   },
   "outputs": [],
   "source": [
    "def calculate_KDF(fluctuations_df,df_y):\n",
    "\n",
    "    x = fluctuations_df['final score'].to_numpy(dtype=float)\n",
    "    y = fluctuations_df[df_y].to_numpy(dtype=float)\n",
    "    xmin = x.min()\n",
    "    xmax = x.max()\n",
    "    ymin = y.min()\n",
    "    ymax = y.max() \n",
    "    # X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "    X, Y = np.mgrid[xmin:xmax:40j, ymin:ymax:40j]\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    values = np.vstack([x, y])\n",
    "    kernel = stats.gaussian_kde(values)\n",
    "    Z = np.reshape(kernel(positions).T, X.shape)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNGoSwsPx8z-"
   },
   "outputs": [],
   "source": [
    "def plot_dist(fluctuations_df,subreddits,axs_list):\n",
    "    fig, axsl = plt.subplots(4,2,figsize=(4,8),sharey=True,tight_layout=True)\n",
    "    fig.text(0.6 , -0.01, r'EmT($c_n$) (true value)', ha='center', fontsize='medium')\n",
    "    fig.text(-0.01, 0.5 , 'prediction', va='center', rotation='vertical', fontsize='medium')\n",
    "    for ax, col in zip(axsl[0], axs_list[:]):\n",
    "        ax.set_title(col.upper(), size='large')\n",
    "    for ax, row in zip(axsl[:,0], subreddits):\n",
    "    # ax.yaxis.set_label_position(\"right\")\n",
    "        ax.set_ylabel(subreddit2title[row.lower()], rotation=0, size='large', horizontalalignment='right')\n",
    "    for indx,axs in enumerate(axsl):\n",
    "        for ind,ax in enumerate(axs):  \n",
    "            x = fluctuations_df[axs_list[ind]].to_numpy(dtype=float)\n",
    "            y = fluctuations_df['final score'].to_numpy(dtype=float)\n",
    "            Z = calculate_KDF(tmp_df.loc[subreddit2range[subreddits[indx]]],axs_list[ind])\n",
    "            xmin = x.min()\n",
    "            xmax = x.max()\n",
    "            ymin = y.min()\n",
    "            ymax = y.max() \n",
    "            ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "                    extent=[xmin, xmax, ymin, ymax],aspect='auto')\n",
    "\n",
    "            #ax.plot(x, y, 'k.', markersize=2)\n",
    "            ax.set_xlim([xmin, xmax])\n",
    "            ax.set_ylim([ymin, ymax])\n",
    "            # ax.plot([0,0],[xmin,ymax],'dimgray',linestyle='dotted')\n",
    "            # ax.plot([xmin,ymax],[0,0],'dimgray',linestyle='dotted')\n",
    "            ax.axvline(color='dimgray',linestyle='dashed')\n",
    "            ax.axhline(color='dimgray',linestyle='dashed')\n",
    "            # ax.set_xlabel(r'$EmT(c_n)$')\n",
    "            # ax.set_ylabel('predictions')\n",
    "    cb = plt.colorbar(            ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "                    extent=[xmin, xmax, ymin, ymax],aspect='auto'), cax = fig.add_axes([0.3, 1.01, .6, 0.01]), orientation='horizontal')\n",
    "    cb.ax.set_title('density', size='large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "WfJ410xWz4Ks",
    "outputId": "2cee0abc-3560-44ba-d8b7-feec2bef1d7b"
   },
   "outputs": [],
   "source": [
    "plot_dist(tmp_df,SUBREDDITS,['mean','xgb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G38Q1gAxRsl"
   },
   "source": [
    "## Robustness tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2czO5jXl1gEP"
   },
   "source": [
    "### Generating 5 different splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6D-_TQNy-DL"
   },
   "outputs": [],
   "source": [
    "def reset_seeds_test(SEED):\n",
    "  random.seed(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  torch.manual_seed(SEED)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  torch.cuda.manual_seed(SEED)\n",
    "  torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHQFa-npyLhy"
   },
   "outputs": [],
   "source": [
    "def split_indices_test(post_df,seed):\n",
    "  \n",
    "    nthreads = len(post_df)     # number of threads\n",
    "    if STRATIFIED:\n",
    "        y = post_df.apply(lambda p: p.score[p.seq_len-1], axis=1).values\n",
    "        bins = np.floor((y - MIN_VALUE)/BIN_WIDTH).astype(int)\n",
    "\n",
    "        reset_seeds_test(seed)\n",
    "        fold_size = int(0.1*len(y))\n",
    "        remaining_inds,valid_inds,_,_ = train_test_split(np.arange(nthreads),y,test_size=fold_size,stratify=bins)\n",
    "        train_inds,test_inds,_,_ = train_test_split(remaining_inds,y[remaining_inds],test_size=fold_size,stratify=bins[remaining_inds])\n",
    "\n",
    "        train_inds = np.sort(train_inds).tolist()\n",
    "        valid_inds = np.sort(valid_inds).tolist()\n",
    "        test_inds  = np.sort(test_inds).tolist()\n",
    "\n",
    "    else:\n",
    "        # divide randomly\n",
    "        reset_seeds_test(seed)\n",
    "        assigned_set = np.random.multinomial(1,[.8,.1,.1],nthreads)\n",
    "        \n",
    "        train_inds = list(np.argwhere(assigned_set[:,0]).ravel())\n",
    "        valid_inds = list(np.argwhere(assigned_set[:,1]).ravel())\n",
    "        test_inds  = list(np.argwhere(assigned_set[:,2]).ravel())\n",
    "\n",
    "    print(f\"Number of training examples: {len(train_inds)}\")\n",
    "    print(f\"Number of validation examples: {len(valid_inds)}\")\n",
    "    print(f\"Number of testing examples: {len(test_inds)}\")\n",
    "\n",
    "    return train_inds, valid_inds, test_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvHT559XxxE0"
   },
   "outputs": [],
   "source": [
    "seeds = [124,125,126,127,128]\n",
    "test_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kci31_C2kCZ7",
    "outputId": "ec98f245-9f2c-41d3-dff0-12833e533031"
   },
   "outputs": [],
   "source": [
    "\n",
    "# TODO: all the constants should be defined or computed in the first cell\n",
    "suffix='_distilbert_filtered_posts.pkl'\n",
    "# if LOW_MEMORY:\n",
    "#     df_list = list()\n",
    "#     for subreddit in SUBREDDITS:\n",
    "#         curr_df = pd.read_pickle(DATADIR+subreddit+suffix)\n",
    "#         curr_df.drop(columns=['features'],inplace=True)\n",
    "#         df_list.append(curr_df)\n",
    "#     post_df = pd.concat((df_list[i]) \\ for i in range(len(SUBREDDITS)))\n",
    "# else:\n",
    "post_df = pd.concat((load_df(DATADIR+subreddit+suffix, MAX_THREAD_LEN) \\\n",
    "                        for subreddit in SUBREDDITS),keys=SUBREDDITS)\n",
    "\n",
    "# post_df = post_df.sample(10000)\n",
    "# print(post_df.loc[subreddit2post[SUBREDDITS[0]]])\n",
    "\n",
    "# TODO: it seems that we are keeping everything if KEEP_TEXT. is this really necessary?\n",
    "if not KEEP_TEXT:\n",
    "  post_df = post_df[['created_utc', 'seq_len','score', 'features', 'filtered_seqlen','valid_branches']]\n",
    "\n",
    "# new strategy to construct observations: follow branches of every discussion tree \n",
    "#post_df.drop(columns=['valid_branches'],inplace=True)\n",
    "\n",
    "if FILTERED:\n",
    "    # dropna on filtered_seqlen, then replace seq_len by filtered_seqlen\n",
    "    post_df.dropna(subset=['filtered_seqlen'], inplace=True)\n",
    "    post_df.filtered_seqlen = post_df.filtered_seqlen.astype(int)\n",
    "\n",
    "    post_df.drop(columns='seq_len',inplace=True)\n",
    "    post_df.rename(columns={'filtered_seqlen':'seq_len'},inplace=True)\n",
    "else:\n",
    "    post_df.drop(columns='filtered_seqlen',inplace=True)\n",
    "\n",
    "print(f'Fraction of threads that had to be truncated: {(post_df.seq_len>(MAX_THREAD_LEN+1)).mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sL6qwJt-jrXi",
    "outputId": "03deca02-f81d-46c3-ae5c-78d0ef0c3cf8"
   },
   "outputs": [],
   "source": [
    "#PART 1\n",
    "print(\"PART1\")\n",
    "prefix = 'unnorm_'\n",
    "shape = [1,post_df.iloc[0].features.shape[-1]]\n",
    "src_m = torch.zeros(shape)\n",
    "src_s = torch.ones(shape)\n",
    "score_m = float(src_m[0,-2])\n",
    "score_s = float(src_s[0,-2])\n",
    "\n",
    "print(f'Average score in dataset is {score_m}')\n",
    "\n",
    "subreddit2range = get_subreddit_range()\n",
    "print(subreddit2range[SUBREDDITS[0]])\n",
    "\n",
    "suffix = \"random\"\n",
    "if STRATIFIED:\n",
    "    suffix += '_strat'\n",
    "\n",
    "# compute weights for Weighted L1 Loss\n",
    "subreddit2weights = get_subreddit_weights(post_df, BIN_WIDTH,MIN_VALUE)\n",
    "print(subreddit2weights)\n",
    "\n",
    "#PART 2\n",
    "print(\"PART2\")\n",
    "\n",
    "print('Creating src')\n",
    "\n",
    "print('Creating y')\n",
    "y = torch.Tensor(post_df.apply(lambda p: p.score[p.seq_len-1], axis=1).values)\n",
    "\n",
    "print('Creating src_len_series')\n",
    "src_len_series = post_df.seq_len-1\n",
    "max_length=MAX_THREAD_LEN\n",
    "\n",
    "src = nn.utils.rnn.pad_sequence(\n",
    "[ (p.features[:min(MAX_THREAD_LEN,p.seq_len-1),:]-src_m)/src_s for index, p in post_df.iterrows()], batch_first=True)\n",
    "print(f\"GRU src tensor size: {src.size()}\")\n",
    "\n",
    "print(f'y tensor size: {y.size()}')\n",
    "tgt = None\n",
    "\n",
    "print('Creating dataset')\n",
    "if USE_GRU:\n",
    "    #dataset = createTensorDataset(src, src_len_series, y, tgt=tgt, max_length=max_length) # all threads, lim 63 comments\n",
    "    dataset = createTensorDataset(src, src_len_series, y, max_length=max_length) # all threads, lim 63 comments\n",
    "    del src\n",
    "\n",
    "del src_len_series, tgt, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNowQHuDxUcN",
    "outputId": "46b63163-537a-486d-ae97-08bf1aaecb16"
   },
   "outputs": [],
   "source": [
    "if type(SUBREDDITS) != list:\n",
    "    SUBREDDITS = list(SUBREDDITS)\n",
    "N_EPOCHS=20 # maximum number of epochs to train the model\n",
    "PATIENCE=3 # constant that controls the Early Stopping mechanism of the grid search for the GRU model\n",
    "SRC_DATASET='all'\n",
    "PREFIX ='random'\n",
    "if STRATIFIED:\n",
    "    PREFIX += '_strat'\n",
    "results_filename=f'{RESULTSDIR}{PREFIX}_{SRC_DATASET}_b{int(2./BIN_WIDTH):02}_f{FILTERED}_n{N_EPOCHS}_p{PATIENCE}_mGRUv1.pkl'\n",
    "print(f'Results file is {results_filename}')\n",
    "for curr_seed in seeds:\n",
    "    train_inds, valid_inds, test_inds  = split_indices_test(post_df,curr_seed)\n",
    "\n",
    "    #PART 3\n",
    "    print(\"PART3\")\n",
    "    train_loader = DataLoader(Subset(dataset,train_inds), batch_size=32, shuffle=True, num_workers=1)\n",
    "    valid_loader = DataLoader(Subset(dataset,valid_inds), batch_size=len(valid_inds), shuffle=False, num_workers=1)\n",
    "    test_loader  = DataLoader(Subset(dataset, test_inds), batch_size=len(test_inds), shuffle=False, num_workers=1)\n",
    "\n",
    "    #PART 4\n",
    "    print(\"PART4\")\n",
    "# load best model\n",
    "\n",
    "    RETRAIN = False\n",
    "    USE_LOSS_BEST = False\n",
    "    USE_BEST_VALIDATION = True\n",
    "    criterion = WeightedL1Loss(subreddit2weights['all'], BIN_WIDTH, MIN_VALUE)\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion_name = lambda x: x.__class__.__name__.split('.')[-1]\n",
    "\n",
    "\n",
    "    # see if the file with best params is available\n",
    "    # results_df = pd.read_pickle(results_filename)\n",
    "\n",
    "    if USE_LOSS_BEST:\n",
    "        best_result = results_df.loc[results_df[criterion_name(criterion)+'_best'].argmin()]\n",
    "    else:\n",
    "        best_result = results_df.loc[results_df[criterion_name(criterion)].argmin()]\n",
    "\n",
    "    # uncomment to load specific model instead\n",
    "    # best_result = results_df.iloc[0]\n",
    "    if RETRAIN:\n",
    "        reset_seeds()\n",
    "        model = models.GRUSentiment(best_result.params)\n",
    "        _, valid_loss, _ = train_over_nepochs( model, train_loader, valid_loader,\n",
    "                                            criterion=criterion, device=device,\n",
    "                                            patience=3, n_epochs=N_EPOCHS)\n",
    "\n",
    "        if USE_BEST_VALIDATION:\n",
    "            model.load_state_dict(torch.load('checkpoint.pt', map_location=lambda storage, loc: storage))\n",
    "\n",
    "    else:\n",
    "        model = models.GRUSentiment(best_result.params)\n",
    "        if USE_BEST_VALIDATION:\n",
    "            model.load_state_dict(best_result.para)\n",
    "        else:\n",
    "            model.load_state_dict(best_result.para_best)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss, outputs = evaluate(model, iter(test_loader), criterion=criterion, device=device, return_predictions=True)\n",
    "    model_yhat = outputs[0][0].cpu().numpy() # extract data from outputs\n",
    "    ilocs = outputs[0][2].cpu().numpy()\n",
    "    model_series = pd.Series(model_yhat.ravel(),index=ilocs)\n",
    "    del outputs\n",
    "\n",
    "    # print model params\n",
    "    print(best_result.params)\n",
    "    print(f'Test loss: {test_loss:.3f}')\n",
    "    test_errors.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06gQib0Bk6ml"
   },
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(f\"Test Errors mean: {np.mean(test_errors)}\")\n",
    "print(f\"Test Errors std: {np.std(test_errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e32afNzSkdm4"
   },
   "source": [
    "### Ramdomly initializing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XDYbIPmkkU0"
   },
   "outputs": [],
   "source": [
    "seeds = [124,125,126,127,128]\n",
    "test_errors2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky87NXIIkt_B"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_inds, valid_inds, test_inds  = split_indices_test(post_df,1234)\n",
    "#PART 3\n",
    "print(\"PART3\")\n",
    "train_loader = DataLoader(Subset(dataset,train_inds), batch_size=32, shuffle=True, num_workers=1)\n",
    "valid_loader = DataLoader(Subset(dataset,valid_inds), batch_size=len(valid_inds), shuffle=False, num_workers=1)\n",
    "test_loader  = DataLoader(Subset(dataset, test_inds), batch_size=len(test_inds), shuffle=False, num_workers=1)\n",
    "for curr_seed in seeds:\n",
    "    #PART 4\n",
    "    print(\"PART4\")\n",
    "    # load best model\n",
    "    # RETRAIN = True\n",
    "    # USE_LOSS_BEST = False\n",
    "    # USE_BEST_VALIDATION = True\n",
    "    criterion = WeightedL1Loss(subreddit2weights['all'], BIN_WIDTH, MIN_VALUE)\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion_name = lambda x: x.__class__.__name__.split('.')[-1]\n",
    "    # see if the file with best params is available\n",
    "    results_df = pd.read_pickle(results_filename)\n",
    "    reset_seeds_test(curr_seed)\n",
    "    best_result = results_df.loc[results_df[criterion_name(criterion)].argmin()]\n",
    "    model = models.GRUSentiment(best_result.params)\n",
    "    _, valid_loss, _ = train_over_nepochs( model, train_loader, valid_loader,\n",
    "                                        criterion=criterion, device=device,\n",
    "                                        patience=3, n_epochs=N_EPOCHS)\n",
    "  \n",
    "\n",
    "    model.load_state_dict(torch.load('checkpoint.pt', map_location=lambda storage, loc: storage))\n",
    "    model.to(device)\n",
    "    test_loss, outputs = evaluate(model, iter(test_loader), criterion=criterion, device=device, return_predictions=True)\n",
    "    model_yhat = outputs[0][0].cpu().numpy() # extract data from outputs\n",
    "    ilocs = outputs[0][2].cpu().numpy()\n",
    "    model_series = pd.Series(model_yhat.ravel(),index=ilocs)\n",
    "    del outputs\n",
    "    # print model params\n",
    "    print(best_result.params)\n",
    "    print(f'Test loss: {test_loss:.3f}')\n",
    "    test_errors2.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJYeMRzIlHMp"
   },
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(f\"Test Errors mean: {np.mean(test_errors2)}\")\n",
    "print(f\"Test Errors std: {np.std(test_errors2)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "REVIEW_EXPERIMENTS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
